{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b5a81e",
   "metadata": {},
   "source": [
    "# 가위바위보 분류기를 만들자.\n",
    "라이브러리 버전을 확인해 봅니다.\n",
    "***\n",
    "사용할 라이브러리 버전을 둘러봅시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da650a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.22.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89928d4",
   "metadata": {},
   "source": [
    "# 디렉토리 만들기\n",
    "이제 클라우드에 실습용 디렉토리 rock_scissor_paper 및 하위 디렉토리들을 만들어, 데이터셋을 올릴 차례입니다!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e7a50",
   "metadata": {},
   "source": [
    "# 디렉토리 만들기  \n",
    "$ mkdir -p ~/aiffel/rock_scissor_paper/scissor  \n",
    "\n",
    "$ mkdir -p ~/aiffel/rock_scissor_paper/rock  \n",
    "\n",
    "$ mkdir -p ~/aiffel/rock_scissor_paper/paper  \n",
    "\n",
    "\n",
    "$ ls -l ~/aiffel/rock_scissor_paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725aaf60",
   "metadata": {},
   "source": [
    "# 클라우드 이미지 압축 해제\n",
    "압축 해제를 하려면 Cloud shell을 열고 아래 명령어를 입력해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df9bcc",
   "metadata": {},
   "source": [
    "# 원하는 디렉토리로 이동 =3\n",
    "$ cd  ~/aiffel/rock_scissor_paper/rock  \n",
    "\n",
    "# 압축 해제 명령어 : unzip <파일명>.zip  \n",
    "\n",
    "$ unzip rock.zip  \n",
    "\n",
    "# 가위, 보에 대해서도 똑같이 실행!\n",
    "\n",
    "$ cd  ~/aiffel/rock_scissor_paper/scissor \n",
    "\n",
    "$ unzip scissor.zip  \n",
    "\n",
    "$ cd  ~/aiffel/rock_scissor_paper/paper  \n",
    "\n",
    "$ unzip paper.zip  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de0011",
   "metadata": {},
   "source": [
    "# 데이터 불러오기  + Resize 하기\n",
    "숫자 손글씨의 경우 이미지 크기가 28x28 이었기 때문에, 우리의 가위, 바위, 보 이미지도 28x28로 만들어야 합니다. 이를 위해서는 PIL 라이브러리를 사용해볼 거예요. 그러려면 먼저 라이브러리를 불러와야 겠죠?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c9f888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b156aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200  images to be resized.\n",
      "200  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c60982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200  images to be resized.\n",
      "200  images resized.\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ffa671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200  images to be resized.\n",
      "200  images resized.\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b451535b",
   "metadata": {},
   "source": [
    "# load_data() 함수로 데이터 읽어오기\n",
    "3개의 클래스 즉   \n",
    "가위:0, 바위:1, 보:2 로 라벨링이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb309b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 600 입니다.\n",
      "x_train shape: (600, 28, 28, 3)\n",
      "y_train shape: (600,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=600):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5039f38e",
   "metadata": {},
   "source": [
    "이미지 한번 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44e08406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79f4fe1",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e1f3cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bc9e4a",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 학습시키기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d0b7ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 1s 18ms/step - loss: 5.4947 - accuracy: 0.5400\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6385 - accuracy: 0.7950\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.2694 - accuracy: 0.8783\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.1953 - accuracy: 0.9250\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.1295 - accuracy: 0.9550\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0859 - accuracy: 0.9667\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0494 - accuracy: 0.9883\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0311 - accuracy: 0.9967\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0261 - accuracy: 0.9983\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0177 - accuracy: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faff4db9a00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5250cfc5",
   "metadata": {},
   "source": [
    "# 얼마나 잘 만들었는지 확인하기(테스트)\n",
    "***\n",
    "300장의 가위바위보 이미지를 만들어 모두 학습에 사용했음.  \n",
    "그러므로 테스트 데이터가 없음. 옆 친구의 이미지 데이터 300장을 받아오기.  \n",
    "그것을 테스트 데이터로 하여 test accuracy를 측정하기. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad5a7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 디렉토리를 생성해서, 친구에게 받은 데이터를 업로드해보세요.\n",
    "# ! mkdir -p ~/aiffel/rock_scissor_paper/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e9ac483",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "테스트 데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "# 이미지 크기 바꾸기 28X28사이즈로. (바위)\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock_test\"\n",
    "resize_images(image_dir_path)\n",
    "# (가위)\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor_test\"\n",
    "resize_images(image_dir_path)\n",
    "# (보)\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper_test\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "\n",
    "# load_data 함수 만들기(테스트용)\n",
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트 데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddce9d9",
   "metadata": {},
   "source": [
    "# 더 좋은 네트워크 만들어보기\n",
    "시험용 데이터 x_test에 대한 인식률 test accuracy가 train accuracy 보다 낮게 나오는 것을 개선하기.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4c85187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 122,051\n",
      "Trainable params: 122,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 16.8446 - accuracy: 0.4017\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.5814 - accuracy: 0.7467\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2805 - accuracy: 0.8750\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.1854 - accuracy: 0.9233\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.1077 - accuracy: 0.9617\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0708 - accuracy: 0.9817\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0418 - accuracy: 0.9900\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0231 - accuracy: 0.9983\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.0212 - accuracy: 0.9967\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "10/10 - 0s - loss: 5.5060 - accuracy: 0.6167\n",
      "test_loss: 5.505963325500488 \n",
      "test_accuracy: 0.6166666746139526\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "\n",
    "# 바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=64\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd97c62",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "처음에 데이터를 학습 시키고 학습시킨 모델을 테스트 했을때 40~50프로의 정확도를 보였다.  \n",
    "목표는 60프로 이상의 정확도를 보이는 것으로, 하이퍼파라미터를 바꾸거나 모델의 학습에 들어가는 데이터를 늘려주는 것으로 실험을 하였다.  \n",
    "하이퍼 파라미터만 조절했을때는 정확도가 크게 변화가 없었다.  \n",
    "그러나 학습시킬 이미지의 양을 300개에서 600개로 늘린 후에 다시 해본 결과 61프로의 정확도가 나왔다.\n",
    "새로운 데이터를 테스트해서 평가하는 것이 쉽지 만은 않은것 같다.  \n",
    "같은 환경에서도 정확도가 달라지는 상황이 생기기 때문에 운? 적인 요소도 있는 것 같다.  \n",
    "어쨋든 좀 더 똑똑한 모델을 만드는데 있어서 중요한 요소는 하이퍼 파라미터와 학습할 데이터의 양인 것을 확인하였다.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
